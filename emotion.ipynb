{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "S48kys0GnQ74",
        "98hWMVDir8wU"
      ],
      "authorship_tag": "ABX9TyOEGQ8LdG73v81KMIsT+tyy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Emad78/Emotion-detection/blob/main/emotion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dadmatools\n",
        "!pip install fasttext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aor4bAMYF7hG",
        "outputId": "6e098751-dc23-4b0c-f6c7-2a6fdff13b92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dadmatools\n",
            "  Downloading dadmatools-1.5.2-py3-none-any.whl (862 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m862.6/862.6 KB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-transformers>=1.1.0\n",
            "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.4/176.4 KB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting supar==1.1.2\n",
            "  Downloading supar-1.1.2-py3-none-any.whl (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.9/87.9 KB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sklearn>=0.0\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: folium>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from dadmatools) (0.12.1.post1)\n",
            "Requirement already satisfied: spacy>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from dadmatools) (3.4.4)\n",
            "Requirement already satisfied: gdown>=4.3.1 in /usr/local/lib/python3.8/dist-packages (from dadmatools) (4.4.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.5/462.5 KB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from dadmatools) (3.7)\n",
            "Collecting py7zr>=0.17.2\n",
            "  Downloading py7zr-0.20.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 KB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyconll>=3.1.0\n",
            "  Downloading pyconll-3.1.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.8/dist-packages (from dadmatools) (1.13.1+cu116)\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Collecting bpemb>=0.3.3\n",
            "  Downloading bpemb-0.3.4-py3-none-any.whl (19 kB)\n",
            "Collecting h5py>=3.3.0\n",
            "  Downloading h5py-3.7.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers>=4.9.1\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting html2text\n",
            "  Downloading html2text-2020.1.16-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.6 in /usr/local/lib/python3.8/dist-packages (from dadmatools) (0.8.10)\n",
            "Requirement already satisfied: gensim>=3.6.0 in /usr/local/lib/python3.8/dist-packages (from dadmatools) (3.6.0)\n",
            "Collecting conllu\n",
            "  Downloading conllu-4.5.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting Deprecated==1.2.6\n",
            "  Downloading Deprecated-1.2.6-py2.py3-none-any.whl (8.1 kB)\n",
            "Collecting NERDA\n",
            "  Downloading NERDA-1.0.0-py3-none-any.whl (23 kB)\n",
            "Collecting hyperopt>=0.2.5\n",
            "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.8/dist-packages (from Deprecated==1.2.6->dadmatools) (1.14.1)\n",
            "Collecting stanza\n",
            "  Downloading stanza-1.4.2-py3-none-any.whl (691 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m691.3/691.3 KB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from supar==1.1.2->dadmatools) (0.3.6)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from bpemb>=0.3.3->dadmatools) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from bpemb>=0.3.3->dadmatools) (2.25.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from bpemb>=0.3.3->dadmatools) (1.21.6)\n",
            "Requirement already satisfied: branca>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from folium>=0.2.1->dadmatools) (0.6.0)\n",
            "Requirement already satisfied: jinja2>=2.9 in /usr/local/lib/python3.8/dist-packages (from folium>=0.2.1->dadmatools) (2.11.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown>=4.3.1->dadmatools) (3.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown>=4.3.1->dadmatools) (1.15.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown>=4.3.1->dadmatools) (4.6.3)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.8/dist-packages (from gensim>=3.6.0->dadmatools) (1.7.3)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.8/dist-packages (from gensim>=3.6.0->dadmatools) (6.3.0)\n",
            "Collecting py4j\n",
            "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 KB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from hyperopt>=0.2.5->dadmatools) (0.16.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.8/dist-packages (from hyperopt>=0.2.5->dadmatools) (3.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from hyperopt>=0.2.5->dadmatools) (2.2.0)\n",
            "Collecting pyzstd>=0.14.4\n",
            "  Downloading pyzstd-0.15.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (378 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m379.0/379.0 KB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodomex>=3.6.6\n",
            "  Downloading pycryptodomex-3.16.0-cp35-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting inflate64>=0.3.1\n",
            "  Downloading inflate64-0.3.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.5/94.5 KB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multivolumefile>=0.2.3\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from py7zr>=0.17.2->dadmatools) (5.4.8)\n",
            "Collecting brotli>=1.0.9\n",
            "  Downloading Brotli-1.0.9-cp38-cp38-manylinux1_x86_64.whl (357 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.2/357.2 KB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyppmd<1.1.0,>=0.18.1\n",
            "  Downloading pyppmd-1.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.7/139.7 KB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pybcj>=0.6.0\n",
            "  Downloading pybcj-1.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 KB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting texttable\n",
            "  Downloading texttable-1.6.7-py2.py3-none-any.whl (10 kB)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.26.54-py3-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 KB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from pytorch-transformers>=1.1.0->dadmatools) (2022.6.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (57.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (2.0.7)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (1.0.9)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (2.4.5)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (8.1.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (0.10.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (3.0.11)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (1.0.4)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (0.10.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (0.7.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (21.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (3.0.8)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (3.3.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (1.10.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.1->dadmatools) (4.4.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.9.1->dadmatools) (6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from NERDA->dadmatools) (1.3.5)\n",
            "Collecting progressbar\n",
            "  Downloading progressbar-2.5.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->dadmatools) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->dadmatools) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2>=2.9->folium>=0.2.1->dadmatools) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy>=3.0.0->dadmatools) (3.0.9)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->bpemb>=0.3.3->dadmatools) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->bpemb>=0.3.3->dadmatools) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->bpemb>=0.3.3->dadmatools) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->bpemb>=0.3.3->dadmatools) (1.24.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.0.0->dadmatools) (0.0.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.0.0->dadmatools) (0.7.9)\n",
            "Collecting botocore<1.30.0,>=1.29.54\n",
            "  Downloading botocore-1.29.54-py3-none-any.whl (10.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 KB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->NERDA->dadmatools) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->NERDA->dadmatools) (2022.7)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests->bpemb>=0.3.3->dadmatools) (1.7.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from stanza->supar==1.1.2->dadmatools) (3.19.6)\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.2.0.tar.gz (240 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.9/240.9 KB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sklearn, progressbar, sacremoses, emoji\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=19b7db8fa8d0dbb67a67b8db6405824306ad29917100ec3b1b74a417823f3699\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/25/f7/1cc0956978ae479e75140219088deb7a36f60459df242b1a72\n",
            "  Building wheel for progressbar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progressbar: filename=progressbar-2.5-py3-none-any.whl size=12081 sha256=bd27aa6c34fa2d3d60e2aebc06fedaa4d81705dd769ab8f30b8fa3665222e590\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/67/ed/d84123843c937d7e7f5ba88a270d11036473144143355e2747\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=7eb64c3c361beb05210ccd526a0986893b2afbb3aa3157937f289b199d53cfee\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-2.2.0-py3-none-any.whl size=234926 sha256=fa0a714c49eedb73531f398df382645f0c9befafd98aaf73011985f66fa79713\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/62/9e/a6b27a681abcde69970dbc0326ff51955f3beac72f15696984\n",
            "Successfully built sklearn progressbar sacremoses emoji\n",
            "Installing collected packages: tokenizers, tf-estimator-nightly, texttable, sklearn, sentencepiece, py4j, progressbar, brotli, urllib3, segtok, sacremoses, pyzstd, pyppmd, pycryptodomex, pyconll, pybcj, multivolumefile, jmespath, inflate64, html2text, h5py, emoji, Deprecated, conllu, py7zr, hyperopt, botocore, stanza, s3transfer, huggingface-hub, bpemb, transformers, boto3, supar, pytorch-transformers, NERDA, dadmatools\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: hyperopt\n",
            "    Found existing installation: hyperopt 0.1.2\n",
            "    Uninstalling hyperopt-0.1.2:\n",
            "      Successfully uninstalled hyperopt-0.1.2\n",
            "Successfully installed Deprecated-1.2.6 NERDA-1.0.0 boto3-1.26.54 botocore-1.29.54 bpemb-0.3.4 brotli-1.0.9 conllu-4.5.2 dadmatools-1.5.2 emoji-2.2.0 h5py-3.7.0 html2text-2020.1.16 huggingface-hub-0.11.1 hyperopt-0.2.7 inflate64-0.3.1 jmespath-1.0.1 multivolumefile-0.2.3 progressbar-2.5 py4j-0.10.9.7 py7zr-0.20.2 pybcj-1.0.1 pyconll-3.1.0 pycryptodomex-3.16.0 pyppmd-1.0.0 pytorch-transformers-1.2.0 pyzstd-0.15.3 s3transfer-0.6.0 sacremoses-0.0.53 segtok-1.5.11 sentencepiece-0.1.97 sklearn-0.0.post1 stanza-1.4.2 supar-1.1.2 texttable-1.6.7 tf-estimator-nightly-2.8.0.dev2021122109 tokenizers-0.13.2 transformers-4.25.1 urllib3-1.26.14\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 KB\u001b[0m \u001b[31m344.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2\n",
            "  Using cached pybind11-2.10.3-py3-none-any.whl (222 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from fasttext) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fasttext) (1.21.6)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp38-cp38-linux_x86_64.whl size=4401394 sha256=729ed5cf6135a09b3771d850fdde14c2c9dca3ce6e30f944ac5adcaba2b6845c\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/61/2a/c54711a91c418ba06ba195b1d78ff24fcaad8592f2a694ac94\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.10.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qcWnOJBNId3T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "outputId": "16e580c9-126b-4679-f3a8-4776631ceea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    122\u001b[0m       'TBE_EPHEM_CREDS_ADDR'] if ephemeral else _os.environ['TBE_CREDS_ADDR']\n\u001b[1;32m    123\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    125\u001b[0m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   request_id = send_request(\n\u001b[1;32m    170\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    100\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    101\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAe44cX9FqzI"
      },
      "outputs": [],
      "source": [
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import fasttext\n",
        "\n",
        "from tensorflow.keras import preprocessing\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional, Input, Embedding, Flatten, SimpleRNN\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow import stack\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report,  accuracy_score\n",
        "from dadmatools.embeddings import get_embedding, get_all_embeddings_info, get_embedding_info\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"drive/MyDrive/Work/CleanData_arman.csv\")\n",
        "data = data[['text', 'label']]\n",
        "\n",
        "train, test = train_test_split(data, test_size=0.3)\n",
        "train.reset_index(drop=True, inplace=True)\n",
        "test.reset_index(drop=True, inplace=True)\n"
      ],
      "metadata": {
        "id": "5hB_zoNPJ17f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train[train.label != 'OTHER']\n",
        "test = test[test.label != 'OTHER']"
      ],
      "metadata": {
        "id": "j9KWO7tazHw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = ''\n",
        "for i in range(len(train)):\n",
        "  text += train.loc[i, 'text'] + \" __label__\"+train.loc[i, 'label'] + \"\\n\"\n",
        "\n",
        "with open(\"drive/MyDrive/Work/train_fasttext.txt\", 'w', encoding='UTF-8') as file:\n",
        "  file.write(text)"
      ],
      "metadata": {
        "id": "5BUxJPe2uDG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fast_text0 = fasttext.FastText.train_supervised(\"drive/MyDrive/Work/train_fasttext.txt\", lr=0.5, epoch=25, wordNgrams=3, bucket=200000, dim=100, loss='ova')\n",
        "fast_text0.save_model(\"drive/MyDrive/Work/fast_text0.model\")\n",
        "fast_text1 = get_embedding('fasttext-commoncrawl-bin')\n",
        "fast_text1.model.save_model('drive/MyDrive/Work/fast_text1.model')\n"
      ],
      "metadata": {
        "id": "PaehndTqLhSP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bfb9b80-dbec-4cfb-fed6-f1eb06775f05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NN Model"
      ],
      "metadata": {
        "id": "jO0757GeCA6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def NN_prepare_data(train, temp):\n",
        "  enc = LabelBinarizer()\n",
        "  test, valid = train_test_split(temp, test_size=0.5)\n",
        "\n",
        "  x_train = np.array(train['text'].apply(fast_text0.get_sentence_vector))\n",
        "  x_test = np.array(test['text'].apply(fast_text0.get_sentence_vector))\n",
        "  x_val = np.array(valid['text'].apply(fast_text0.get_sentence_vector))\n",
        "\n",
        "  x_train1 = np.array(train['text'].apply(fast_text1.embedding_text))\n",
        "  x_test1 = np.array(test['text'].apply(fast_text1.embedding_text))\n",
        "  x_val1 = np.array(valid['text'].apply(fast_text1.embedding_text))\n",
        "\n",
        "  for i in range(len(x_train)):\n",
        "    x_train[i] = np.concatenate((x_train[i], x_train1[i]), axis=0)\n",
        "\n",
        "  for i in range(len(x_test)):\n",
        "    x_test[i] = np.concatenate((x_test[i], x_test1[i]), axis=0)\n",
        "\n",
        "  for i in range(len(x_val)):\n",
        "    x_val[i] = np.concatenate((x_val[i], x_val1[i]), axis=0)\n",
        "\n",
        "\n",
        "  enc.fit(train['label'])\n",
        "  y_train = enc.transform(train['label'])\n",
        "  y_test = enc.transform(test['label'])\n",
        "  y_val = enc.transform(valid['label'])\n",
        "\n",
        "  return x_train, y_train, x_test, y_test, x_val, y_val, enc"
      ],
      "metadata": {
        "id": "EkcJAjhcl5Br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(input_size, output_size):\n",
        "  model = Sequential()\n",
        "  model.add(Input(input_size))\n",
        "  model.add(Dense(10, activation='relu'))\n",
        "  model.add(Dense(output_size, activation='softmax'))\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "y3nwx8j6VwCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y, x_test, y_test, x_val, y_val, enc = prepare_data(train, test)"
      ],
      "metadata": {
        "id": "6zIxMkjkWHns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(400, 6)\n",
        "print(model.summary())\n",
        "model.fit(stack(x),y, epochs=80, batch_size=128, validation_data=(stack(x_val), y_val))\n"
      ],
      "metadata": {
        "id": "a9uIJKwPXUA3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90a445eb-ce04-40f9-8301-73f139afe43b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 10)                4010      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 6)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,076\n",
            "Trainable params: 4,076\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "30/30 [==============================] - 1s 8ms/step - loss: 1.7401 - acc: 0.4201 - val_loss: 1.7171 - val_acc: 0.5104\n",
            "Epoch 2/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.6028 - acc: 0.7225 - val_loss: 1.6319 - val_acc: 0.5031\n",
            "Epoch 3/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.4488 - acc: 0.7376 - val_loss: 1.5534 - val_acc: 0.5117\n",
            "Epoch 4/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.3063 - acc: 0.7526 - val_loss: 1.4844 - val_acc: 0.5178\n",
            "Epoch 5/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.1740 - acc: 0.7768 - val_loss: 1.4241 - val_acc: 0.5350\n",
            "Epoch 6/80\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 1.0507 - acc: 0.8356 - val_loss: 1.3668 - val_acc: 0.5595\n",
            "Epoch 7/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.9349 - acc: 0.8746 - val_loss: 1.3165 - val_acc: 0.5742\n",
            "Epoch 8/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8261 - acc: 0.8909 - val_loss: 1.2694 - val_acc: 0.5890\n",
            "Epoch 9/80\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.7252 - acc: 0.9071 - val_loss: 1.2277 - val_acc: 0.6012\n",
            "Epoch 10/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6328 - acc: 0.9229 - val_loss: 1.1910 - val_acc: 0.6049\n",
            "Epoch 11/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.5486 - acc: 0.9431 - val_loss: 1.1526 - val_acc: 0.6221\n",
            "Epoch 12/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.4729 - acc: 0.9675 - val_loss: 1.1233 - val_acc: 0.6184\n",
            "Epoch 13/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.4065 - acc: 0.9852 - val_loss: 1.0962 - val_acc: 0.6294\n",
            "Epoch 14/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.3482 - acc: 0.9960 - val_loss: 1.0715 - val_acc: 0.6380\n",
            "Epoch 15/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.2982 - acc: 0.9987 - val_loss: 1.0519 - val_acc: 0.6380\n",
            "Epoch 16/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.2556 - acc: 0.9989 - val_loss: 1.0382 - val_acc: 0.6405\n",
            "Epoch 17/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.2205 - acc: 0.9989 - val_loss: 1.0257 - val_acc: 0.6454\n",
            "Epoch 18/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.1915 - acc: 0.9987 - val_loss: 1.0151 - val_acc: 0.6540\n",
            "Epoch 19/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.1672 - acc: 0.9989 - val_loss: 1.0086 - val_acc: 0.6491\n",
            "Epoch 20/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.1469 - acc: 0.9989 - val_loss: 1.0031 - val_acc: 0.6515\n",
            "Epoch 21/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.1298 - acc: 0.9989 - val_loss: 0.9986 - val_acc: 0.6589\n",
            "Epoch 22/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.1155 - acc: 0.9989 - val_loss: 0.9949 - val_acc: 0.6564\n",
            "Epoch 23/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.1032 - acc: 0.9992 - val_loss: 0.9924 - val_acc: 0.6626\n",
            "Epoch 24/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0927 - acc: 0.9989 - val_loss: 0.9922 - val_acc: 0.6638\n",
            "Epoch 25/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0837 - acc: 0.9992 - val_loss: 0.9920 - val_acc: 0.6650\n",
            "Epoch 26/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0758 - acc: 0.9992 - val_loss: 0.9911 - val_acc: 0.6650\n",
            "Epoch 27/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0689 - acc: 0.9992 - val_loss: 0.9908 - val_acc: 0.6675\n",
            "Epoch 28/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0631 - acc: 0.9992 - val_loss: 0.9917 - val_acc: 0.6675\n",
            "Epoch 29/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0579 - acc: 0.9992 - val_loss: 0.9935 - val_acc: 0.6675\n",
            "Epoch 30/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0533 - acc: 0.9992 - val_loss: 0.9937 - val_acc: 0.6675\n",
            "Epoch 31/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0492 - acc: 0.9992 - val_loss: 0.9945 - val_acc: 0.6675\n",
            "Epoch 32/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0457 - acc: 0.9992 - val_loss: 0.9967 - val_acc: 0.6699\n",
            "Epoch 33/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0424 - acc: 0.9992 - val_loss: 0.9976 - val_acc: 0.6687\n",
            "Epoch 34/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0396 - acc: 0.9992 - val_loss: 1.0005 - val_acc: 0.6675\n",
            "Epoch 35/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0370 - acc: 0.9992 - val_loss: 1.0028 - val_acc: 0.6736\n",
            "Epoch 36/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0347 - acc: 0.9992 - val_loss: 1.0056 - val_acc: 0.6687\n",
            "Epoch 37/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0326 - acc: 0.9992 - val_loss: 1.0091 - val_acc: 0.6724\n",
            "Epoch 38/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0305 - acc: 0.9992 - val_loss: 1.0100 - val_acc: 0.6761\n",
            "Epoch 39/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0288 - acc: 0.9992 - val_loss: 1.0117 - val_acc: 0.6761\n",
            "Epoch 40/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0272 - acc: 0.9992 - val_loss: 1.0130 - val_acc: 0.6724\n",
            "Epoch 41/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0257 - acc: 0.9992 - val_loss: 1.0149 - val_acc: 0.6724\n",
            "Epoch 42/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0243 - acc: 0.9992 - val_loss: 1.0199 - val_acc: 0.6736\n",
            "Epoch 43/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0231 - acc: 0.9992 - val_loss: 1.0211 - val_acc: 0.6785\n",
            "Epoch 44/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0220 - acc: 0.9992 - val_loss: 1.0223 - val_acc: 0.6785\n",
            "Epoch 45/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0210 - acc: 0.9992 - val_loss: 1.0268 - val_acc: 0.6761\n",
            "Epoch 46/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0199 - acc: 0.9992 - val_loss: 1.0278 - val_acc: 0.6785\n",
            "Epoch 47/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0190 - acc: 0.9989 - val_loss: 1.0313 - val_acc: 0.6761\n",
            "Epoch 48/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0181 - acc: 0.9989 - val_loss: 1.0335 - val_acc: 0.6785\n",
            "Epoch 49/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0174 - acc: 0.9992 - val_loss: 1.0362 - val_acc: 0.6773\n",
            "Epoch 50/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0166 - acc: 0.9992 - val_loss: 1.0373 - val_acc: 0.6785\n",
            "Epoch 51/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0159 - acc: 0.9992 - val_loss: 1.0423 - val_acc: 0.6798\n",
            "Epoch 52/80\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0154 - acc: 0.9989 - val_loss: 1.0450 - val_acc: 0.6785\n",
            "Epoch 53/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0148 - acc: 0.9992 - val_loss: 1.0430 - val_acc: 0.6810\n",
            "Epoch 54/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0142 - acc: 0.9992 - val_loss: 1.0475 - val_acc: 0.6785\n",
            "Epoch 55/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0136 - acc: 0.9992 - val_loss: 1.0516 - val_acc: 0.6798\n",
            "Epoch 56/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0130 - acc: 0.9992 - val_loss: 1.0540 - val_acc: 0.6773\n",
            "Epoch 57/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0126 - acc: 0.9992 - val_loss: 1.0554 - val_acc: 0.6773\n",
            "Epoch 58/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0122 - acc: 0.9989 - val_loss: 1.0588 - val_acc: 0.6785\n",
            "Epoch 59/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0117 - acc: 0.9992 - val_loss: 1.0627 - val_acc: 0.6773\n",
            "Epoch 60/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0117 - acc: 0.9987 - val_loss: 1.0746 - val_acc: 0.6724\n",
            "Epoch 61/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0114 - acc: 0.9992 - val_loss: 1.0707 - val_acc: 0.6785\n",
            "Epoch 62/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0107 - acc: 0.9992 - val_loss: 1.0738 - val_acc: 0.6785\n",
            "Epoch 63/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0104 - acc: 0.9989 - val_loss: 1.0738 - val_acc: 0.6761\n",
            "Epoch 64/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0099 - acc: 0.9992 - val_loss: 1.0761 - val_acc: 0.6748\n",
            "Epoch 65/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0097 - acc: 0.9992 - val_loss: 1.0781 - val_acc: 0.6798\n",
            "Epoch 66/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0093 - acc: 0.9992 - val_loss: 1.0797 - val_acc: 0.6785\n",
            "Epoch 67/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0092 - acc: 0.9992 - val_loss: 1.0818 - val_acc: 0.6785\n",
            "Epoch 68/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0089 - acc: 0.9992 - val_loss: 1.0826 - val_acc: 0.6785\n",
            "Epoch 69/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0086 - acc: 0.9992 - val_loss: 1.0857 - val_acc: 0.6773\n",
            "Epoch 70/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0083 - acc: 0.9989 - val_loss: 1.0863 - val_acc: 0.6785\n",
            "Epoch 71/80\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0082 - acc: 0.9992 - val_loss: 1.0897 - val_acc: 0.6748\n",
            "Epoch 72/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0081 - acc: 0.9989 - val_loss: 1.0934 - val_acc: 0.6773\n",
            "Epoch 73/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0077 - acc: 0.9992 - val_loss: 1.0935 - val_acc: 0.6773\n",
            "Epoch 74/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0075 - acc: 0.9992 - val_loss: 1.0975 - val_acc: 0.6773\n",
            "Epoch 75/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0073 - acc: 0.9992 - val_loss: 1.0997 - val_acc: 0.6773\n",
            "Epoch 76/80\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.0072 - acc: 0.9992 - val_loss: 1.1000 - val_acc: 0.6773\n",
            "Epoch 77/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0071 - acc: 0.9989 - val_loss: 1.1032 - val_acc: 0.6798\n",
            "Epoch 78/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0068 - acc: 0.9989 - val_loss: 1.1055 - val_acc: 0.6773\n",
            "Epoch 79/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0067 - acc: 0.9992 - val_loss: 1.1064 - val_acc: 0.6748\n",
            "Epoch 80/80\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0065 - acc: 0.9989 - val_loss: 1.1089 - val_acc: 0.6798\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efd13e09490>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import one_hot, argmax\n",
        "pre = model.predict(stack(x_test))\n",
        "y_pred = []\n",
        "for p in pre:\n",
        "  s = len(p)*[0]\n",
        "  s[argmax(p)] = 1\n",
        "  y_pred.append(s)\n",
        "\n",
        "y_pred = enc.inverse_transform(np.array(y_pred))\n",
        "actual = enc.inverse_transform(y_test)\n",
        "model.evaluate(stack(x_test), y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uukQaxuqbYyJ",
        "outputId": "dfbfe96c-6fbc-4003-f4c3-6e6ff5d0ca21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26/26 [==============================] - 0s 1ms/step\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.2097 - acc: 0.6638\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.2097331285476685, 0.6638036966323853]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(actual, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8gyTwyaG-q9",
        "outputId": "2057bc91-984b-4669-fec7-2195396c1763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       ANGRY       0.71      0.74      0.72       162\n",
            "        FEAR       0.81      0.80      0.81       112\n",
            "       HAPPY       0.53      0.68      0.59       117\n",
            "        HATE       0.71      0.68      0.70        84\n",
            "         SAD       0.65      0.61      0.63       201\n",
            "    SURPRISE       0.70      0.58      0.63       139\n",
            "\n",
            "    accuracy                           0.67       815\n",
            "   macro avg       0.69      0.68      0.68       815\n",
            "weighted avg       0.68      0.67      0.68       815\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('drive/MyDrive/Work/6class_NN.model', 'wb') as file:\n",
        "  pickle.dump(model, file)"
      ],
      "metadata": {
        "id": "ynO1Lk2CSjF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# classic"
      ],
      "metadata": {
        "id": "S48kys0GnQ74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def prepare_data(train, test):\n",
        "  enc = LabelBinarizer()\n",
        "  \n",
        "  x_train = list(train['text'].apply(fast_text0.get_sentence_vector))\n",
        "  x_test = list(test['text'].apply(fast_text0.get_sentence_vector))\n",
        "  \n",
        "  x_train1 = list(train['text'].apply(fast_text1.embedding_text))\n",
        "  x_test1 = list(test['text'].apply(fast_text1.embedding_text))\n",
        "  \n",
        "  for i in range(len(x_train)):\n",
        "    x_train[i] = list(np.concatenate((x_train[i], x_train1[i]), axis=0))\n",
        "\n",
        "  for i in range(len(x_test)):\n",
        "    x_test[i] = list(np.concatenate((x_test[i], x_test1[i]), axis=0))\n",
        "\n",
        "\n",
        "  y_train = (train['label'])\n",
        "  y_test = (test['label'])\n",
        "\n",
        "  return x_train, y_train, x_test, y_test"
      ],
      "metadata": {
        "id": "QQRdntPzshQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y, x_test, y_test = prepare_data(train, test)"
      ],
      "metadata": {
        "id": "VfsVwm0YrAlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm = SVC(kernel='rbf')\n",
        "svm.fit(x, y)\n",
        "pre = svm.predict(x_test)"
      ],
      "metadata": {
        "id": "jKzwRK6JnSwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=25)\n",
        "knn.fit(x, y)\n",
        "pre = knn.predict(x_test)"
      ],
      "metadata": {
        "id": "4U2Y03VFKm-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp = MLPClassifier(random_state=10, max_iter=1000)\n",
        "mlp.fit(x, y)\n",
        "pre = mlp.predict(x_test)\n"
      ],
      "metadata": {
        "id": "uVGTXXODK-OX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, pre))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBgSWrGfCoSJ",
        "outputId": "63f5dab1-c022-49d3-88f1-73831569f9a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       ANGRY       0.63      0.61      0.62       335\n",
            "        FEAR       0.80      0.79      0.80       235\n",
            "       HAPPY       0.53      0.54      0.54       257\n",
            "        HATE       0.69      0.64      0.66       176\n",
            "       OTHER       0.37      0.52      0.43       320\n",
            "         SAD       0.60      0.51      0.55       376\n",
            "    SURPRISE       0.57      0.45      0.51       252\n",
            "\n",
            "    accuracy                           0.57      1951\n",
            "   macro avg       0.60      0.58      0.59      1951\n",
            "weighted avg       0.59      0.57      0.57      1951\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, pre)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzIGotX-Bdbn",
        "outputId": "805449e1-ba14-4cdf-e297-1b94be9650b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6705521472392638"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('drive/MyDrive/Work/6class_svm.model', 'wb') as file:\n",
        "  pickle.dump(svm, file)\n",
        "with open('drive/MyDrive/Work/6class_mlp.model', 'wb') as file:\n",
        "  pickle.dump(mlp, file)\n",
        "with open('drive/MyDrive/Work/6class_knn.model', 'wb') as file:\n",
        "  pickle.dump(knn, file)"
      ],
      "metadata": {
        "id": "s5vFh9E08zYY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}